爬虫:   
    自动获取网互联网信息的程序或脚本,提取网页中有价值的数据.
    - 可以爬某个网站下的某些数据.
    - 也可以爬全世界所有网站下的某些数据.

互联网: 
    无数网页组成.
    网页使用 URL  网址访问. 
    网页使用 HTTP 协议传输.
    网页使用 HTML 语言编写.

互联网就像一张超级巨大的蜘蛛网. 爬虫就是里面的一中小蜘蛛.
每个网页都有很多链接(URL).理论上通过这些链接可以通到世界上任意一个网站.
爬虫日夜不停的去查看所有网页.遇到有价值的东西就下载下来.




❤️爬虫作用:❤️
  ❗️搜索引擎的基础!❗️
    你写了一篇文章.发表到网络上. 谷歌就能搜索到你的文章! 为什么?!
    谷歌有个数据库. 哪篇文章 的关键词是什么.
    互联网这么大,靠人工维护这个数据库是不现实的,
    只有爬虫才能收录网页. 只有你的网页被收录了 你的网页才会出现在搜索结果中

你要研究SEO. 就得知道爬虫.

做爬虫去 收集大类的代理服务器!!! 不同的服务器就是不同的IP.
这些就可以刷票了!!!!

免费的东西总是不稳定的. 定期更新IP地址, 删除无效的服务器.


可以抓twitter 的说说.. 每天几亿条数据.
下下来要存到哪里呢...
公司可以用集群啊. hadoop. spark... 
穷人只能自己台式机组raid.

储存数据肯定用数据库了. mysql.
几十亿的数据. 必须大量优化啊. 不然查一条都要半天...
要可以几秒内 读取到出某条数据 才行...


Python 是神器. 就因为谷歌用这个 我就绝对学python.而不是php perl..
Python 很简单!!! 没编程的也能入门.








获取某网站所有用户的头像.
更具头像被点击的次数.来预测出最受欢迎的头像


抓取 facebook 上的 sleep关键词. 来判断出大家的睡眠时间..
因为看来很多人喜欢在睡前会说一声我睡了。




    方便的获取数据!!!
    喜欢看美女图片? 写个爬虫把某网站所有的图片都下下来 慢慢看.
    喜欢看电影?     写个爬虫把某网站所有种子都下下来,慢慢下载.
    喜欢某个妹子?   写个爬虫把她所有说说都下下来研究
    喜欢秒杀超值物品 写个爬虫.... 还是脚本 ??



爬虫实现原理:
  抓取网页, 
    储存网页, 
      分析网页. 
        显示结果; 
          抓取下一个网页. 储存,分析, 重复循环.


抓取网页:
  平时上网,浏览器中输入网址,按下回车. 显示网页内容.
    其实就是 发送请求 + 接收请求
      发送请求里面 有要访问的网址
      接收请求里面 有要显示的内容
        浏览器都可以上网.更别说用终端了.




爬虫储备知识:
  下载网页:urllib urllib2
  解析网页: BeautifulSoup，熟悉JQuery的可以用Pyquery
  提交请求.使用Requests来提交各种类型的请求，支持重定向，cookies等。
.使用Selenium，模拟浏览器提交类似用户的操作，处理js动态产生的网页














❤️爬取数据❤️
















